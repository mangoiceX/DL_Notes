### 优化算法

##### 指数加权平均数

偏差修正（系数之和近似于1）帮助训练早期的结果更加正确。

$v_t=\beta v_{t-1}+(1-\beta)\theta_t$

其中，$v_t$表示前t个数据的平均数，$\theta_t$表示第t个数据。

利用上式计算后，再$\frac{v_t}{1-\beta^t}$，因为$\beta$<1,所以当t很大是，分母接近1，修正不再有效。

#### Momentum

求梯度的指数加权平均数

![image-20210727104943529](C:\Users\xmh\AppData\Roaming\Typora\typora-user-images\image-20210727104943529.png)

#####  RMSprop

![image-20210727110505375](C:\Users\xmh\AppData\Roaming\Typora\typora-user-images\image-20210727110505375.png)

#### Adam

![image-20210727111442445](C:\Users\xmh\AppData\Roaming\Typora\typora-user-images\image-20210727111442445.png)

#### 学习率衰减

#### 局部最优问题

极值要求每个方向的导数等于0，当参数的维度比较大时，极值发生的概率很小。大都时候碰到的是鞍点。