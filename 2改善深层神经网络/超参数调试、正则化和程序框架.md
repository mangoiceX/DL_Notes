#### 超参数调试、正则化和程序框架

##### 参数调试

重要性（吴恩达）

学习, mini-batch size, hidden units > layers, learning rate decay

随机取值，精确搜索，由粗糙到精细的搜索过程。

##### 合适范围

学习率在对数尺度进行搜索。

##### 超参数训练实践

精调一个模型Baby setting one model

同时训练多个模型Training many model in parallel

##### 正则化网络

通常对激活函数的输出值进行归一化。

如果使用batch norm的话，可以去除wa+b的b，因为batch norm首先会标准化，会消除掉b的影响。

他可以使权重比你的网络更滞后或更深层。

covariate shift.

![image-20210728110134985](C:\Users\xmh\AppData\Roaming\Typora\typora-user-images\image-20210728110134985.png)

第3层和第4层的参数是为了找到一个从a2到y良好的映射关系。但是第1层和第2层的参数会一直发生改变，导致a2会发生covariate shift。batch norm的目的就是减少隐藏值分布的变化。限制了前层的参数更新会影响数值分布的程度。减少了前层参数的作用与后层参数作用的联系，使得每层网络都可以自己学习。

batch norm会带来噪声，有轻微的正则化效果。

测试的时候无法计算mini-batch的方差（只有一个或很少数样本时），此时，可以计算之前该层所有的均值和方差的加权指数平均数。

